{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We briefly introduced the concept of data leakage in the previous sprint  when we discussed using pipelines for preprocessing and model fitting. In general, and especially if you are using cross-validation, it's good to be conscious of when, where, and why data leakage can occur. This module is focused on learning how to work with data that isn't already prepared for modeling. Not only do we need to know which features to use and if our target is appropriate, but we also need to protect again information leaking into either our testing data or from certain features.\n",
    "\n",
    "The two main types of leakage are leaky features (predictors) and a leaky validation or testing process. \n",
    "\n",
    "### Leaky Features\n",
    "\n",
    "This type of leakage occurs when you have a feature that has access to data that won't be available when you actually use the model on new data (outside of the test set) to make predictions. This could happen if you adjust the values in that feature *after* you determined the values in your target array. \n",
    "\n",
    "For example, if we were predicting if someone has heart disease (True/False) and used a feature called \"BP_meds\" (indicating if the individual is taking blood pressure medication), we might have a problem. If someone is taking this medication, it might be because they have heart disease and are being treated. But the value in this column could have been changed *after* they were diagnosed with heart disease.\n",
    "\n",
    "### Leaky Testing Process\n",
    "\n",
    "The other type of leak can happen when your validation data \"learns\" from the training data. If you are preprocessing the data, such as filling in missing values with the `Imputer` or standardizing, you might accidentally be using the entire data set. In this case, it's important to apply the preprocessing steps separately to the training and testing data which will prevent the testing data from learning anything from the training set.\n",
    "\n",
    "Now that we are more familiar with these two different types of data leakage, let's explore our real-world weather data from the previous objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along\n",
    "\n",
    "We introduced the Australian weather data set earlier and explored it briefly to decide on the prediction target, which was if it was going to rain on the day following the measurements. Let's look more closely at each of the features (predictors) to see if any of them could present leakage problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RISK_MM</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
       "0           W           44.0          W  ...        22.0       1007.7   \n",
       "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
       "2         WSW           46.0          W  ...        30.0       1007.6   \n",
       "3          NE           24.0         SE  ...        16.0       1017.6   \n",
       "4           W           41.0        ENE  ...        33.0       1010.8   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
       "0       1007.1       8.0       NaN     16.9     21.8         No      0.0   \n",
       "1       1007.8       NaN       NaN     17.2     24.3         No      0.0   \n",
       "2       1008.7       NaN       2.0     21.0     23.2         No      0.0   \n",
       "3       1012.8       NaN       NaN     18.1     26.5         No      1.0   \n",
       "4       1006.0       7.0       8.0     17.8     29.7         No      0.2   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries, load data, and view\n",
    "import pandas as pd\n",
    "weather = pd.read_csv('weatherAUS.csv')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we identify any possible \"leaky features\" we should decide which features to use and the necessary preprocessing steps. Let's look at each type of variable (numeric and categorical) in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142193</td>\n",
       "      <td>142193</td>\n",
       "      <td>132863</td>\n",
       "      <td>132180</td>\n",
       "      <td>138415</td>\n",
       "      <td>140787</td>\n",
       "      <td>142193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3436</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2013-10-08</td>\n",
       "      <td>Canberra</td>\n",
       "      <td>W</td>\n",
       "      <td>N</td>\n",
       "      <td>SE</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>49</td>\n",
       "      <td>3418</td>\n",
       "      <td>9780</td>\n",
       "      <td>11393</td>\n",
       "      <td>10663</td>\n",
       "      <td>109332</td>\n",
       "      <td>110316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date  Location WindGustDir WindDir9am WindDir3pm RainToday  \\\n",
       "count       142193    142193      132863     132180     138415    140787   \n",
       "unique        3436        49          16         16         16         2   \n",
       "top     2013-10-08  Canberra           W          N         SE        No   \n",
       "freq            49      3418        9780      11393      10663    109332   \n",
       "\n",
       "       RainTomorrow  \n",
       "count        142193  \n",
       "unique            2  \n",
       "top              No  \n",
       "freq         110316  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the statistics of categorical variables \n",
    "weather.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RISK_MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>141556.000000</td>\n",
       "      <td>141871.000000</td>\n",
       "      <td>140787.000000</td>\n",
       "      <td>81350.000000</td>\n",
       "      <td>74377.000000</td>\n",
       "      <td>132923.000000</td>\n",
       "      <td>140845.000000</td>\n",
       "      <td>139563.000000</td>\n",
       "      <td>140419.000000</td>\n",
       "      <td>138583.000000</td>\n",
       "      <td>128179.000000</td>\n",
       "      <td>128212.000000</td>\n",
       "      <td>88536.000000</td>\n",
       "      <td>85099.000000</td>\n",
       "      <td>141289.000000</td>\n",
       "      <td>139467.000000</td>\n",
       "      <td>142193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.186400</td>\n",
       "      <td>23.226784</td>\n",
       "      <td>2.349974</td>\n",
       "      <td>5.469824</td>\n",
       "      <td>7.624853</td>\n",
       "      <td>39.984292</td>\n",
       "      <td>14.001988</td>\n",
       "      <td>18.637576</td>\n",
       "      <td>68.843810</td>\n",
       "      <td>51.482606</td>\n",
       "      <td>1017.653758</td>\n",
       "      <td>1015.258204</td>\n",
       "      <td>4.437189</td>\n",
       "      <td>4.503167</td>\n",
       "      <td>16.987509</td>\n",
       "      <td>21.687235</td>\n",
       "      <td>2.360682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.403283</td>\n",
       "      <td>7.117618</td>\n",
       "      <td>8.465173</td>\n",
       "      <td>4.188537</td>\n",
       "      <td>3.781525</td>\n",
       "      <td>13.588801</td>\n",
       "      <td>8.893337</td>\n",
       "      <td>8.803345</td>\n",
       "      <td>19.051293</td>\n",
       "      <td>20.797772</td>\n",
       "      <td>7.105476</td>\n",
       "      <td>7.036677</td>\n",
       "      <td>2.887016</td>\n",
       "      <td>2.720633</td>\n",
       "      <td>6.492838</td>\n",
       "      <td>6.937594</td>\n",
       "      <td>8.477969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.500000</td>\n",
       "      <td>-4.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>980.500000</td>\n",
       "      <td>977.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.200000</td>\n",
       "      <td>-5.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.600000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1012.900000</td>\n",
       "      <td>1010.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1017.600000</td>\n",
       "      <td>1015.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.800000</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1022.400000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1041.000000</td>\n",
       "      <td>1039.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>46.700000</td>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MinTemp        MaxTemp       Rainfall   Evaporation  \\\n",
       "count  141556.000000  141871.000000  140787.000000  81350.000000   \n",
       "mean       12.186400      23.226784       2.349974      5.469824   \n",
       "std         6.403283       7.117618       8.465173      4.188537   \n",
       "min        -8.500000      -4.800000       0.000000      0.000000   \n",
       "25%         7.600000      17.900000       0.000000      2.600000   \n",
       "50%        12.000000      22.600000       0.000000      4.800000   \n",
       "75%        16.800000      28.200000       0.800000      7.400000   \n",
       "max        33.900000      48.100000     371.000000    145.000000   \n",
       "\n",
       "           Sunshine  WindGustSpeed   WindSpeed9am   WindSpeed3pm  \\\n",
       "count  74377.000000  132923.000000  140845.000000  139563.000000   \n",
       "mean       7.624853      39.984292      14.001988      18.637576   \n",
       "std        3.781525      13.588801       8.893337       8.803345   \n",
       "min        0.000000       6.000000       0.000000       0.000000   \n",
       "25%        4.900000      31.000000       7.000000      13.000000   \n",
       "50%        8.500000      39.000000      13.000000      19.000000   \n",
       "75%       10.600000      48.000000      19.000000      24.000000   \n",
       "max       14.500000     135.000000     130.000000      87.000000   \n",
       "\n",
       "         Humidity9am    Humidity3pm    Pressure9am    Pressure3pm  \\\n",
       "count  140419.000000  138583.000000  128179.000000  128212.000000   \n",
       "mean       68.843810      51.482606    1017.653758    1015.258204   \n",
       "std        19.051293      20.797772       7.105476       7.036677   \n",
       "min         0.000000       0.000000     980.500000     977.100000   \n",
       "25%        57.000000      37.000000    1012.900000    1010.400000   \n",
       "50%        70.000000      52.000000    1017.600000    1015.200000   \n",
       "75%        83.000000      66.000000    1022.400000    1020.000000   \n",
       "max       100.000000     100.000000    1041.000000    1039.600000   \n",
       "\n",
       "           Cloud9am      Cloud3pm        Temp9am        Temp3pm        RISK_MM  \n",
       "count  88536.000000  85099.000000  141289.000000  139467.000000  142193.000000  \n",
       "mean       4.437189      4.503167      16.987509      21.687235       2.360682  \n",
       "std        2.887016      2.720633       6.492838       6.937594       8.477969  \n",
       "min        0.000000      0.000000      -7.200000      -5.400000       0.000000  \n",
       "25%        1.000000      2.000000      12.300000      16.600000       0.000000  \n",
       "50%        5.000000      5.000000      16.700000      21.100000       0.000000  \n",
       "75%        7.000000      7.000000      21.600000      26.400000       0.800000  \n",
       "max        9.000000      9.000000      40.200000      46.700000     371.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the statistics of the numeric variables \n",
    "weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration: Null Values\n",
    "\n",
    "From the above DataFrame descriptions, we can see that there are a lot of null values in some of the columns. We'll take a more detailed look at how many are missing in what columns. The plot below is created using a module available at [this repository](https://github.com/ResidentMario/missingno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp            637\n",
       "MaxTemp            322\n",
       "Rainfall          1406\n",
       "Evaporation      60843\n",
       "Sunshine         67816\n",
       "WindGustDir       9330\n",
       "WindGustSpeed     9270\n",
       "WindDir9am       10013\n",
       "WindDir3pm        3778\n",
       "WindSpeed9am      1348\n",
       "WindSpeed3pm      2630\n",
       "Humidity9am       1774\n",
       "Humidity3pm       3610\n",
       "Pressure9am      14014\n",
       "Pressure3pm      13981\n",
       "Cloud9am         53657\n",
       "Cloud3pm         57094\n",
       "Temp9am            904\n",
       "Temp3pm           2726\n",
       "RainToday         1406\n",
       "RISK_MM              0\n",
       "RainTomorrow         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-82cd9c658573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmsno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "msno.matrix(weather)\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mod1_obj1_missingNA.png](https://raw.githubusercontent.com/LambdaSchool/data-science-canvas-images/main/unit_2/sprint_3/mod1_obj1_missingNA.png)\n",
    "\n",
    "We have four columns with a large number of null values. If we were doing this analysis for a competition (or for an actual data science job!) we would want to more carefully explore the missing values. Since these columns are missing about 40% of their data (or more), we're going to drop them for this analysis. For the other missing values, we'll use an `Imputer` in the preprocessing step.\n",
    "\n",
    "To simplify the analysis for later, we'll also drop the `Location` column. Again, this information might be important for a more detailed model, but we're trying to keep this process simple so that we can focus on identifying the leaky features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with high-percentage of missing values\n",
    "cols_drop = ['Location', 'Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm']\n",
    "weather_drop = weather.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning: Datetime\n",
    "\n",
    "We have a date column which could be converted to a datetime object; we could then use just the 'month' value in our model, as the full date would be too specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime, extract month\n",
    "weather_drop['Date'] = pd.to_datetime(weather_drop['Date'], infer_datetime_format=True).dt.month\n",
    "weather_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing: Pipeline\n",
    "\n",
    "We'll separate our features into numeric and categorical types and then perform the following steps.\n",
    "\n",
    "#### Numeric Features\n",
    "\n",
    "As some of the numeric features are on very different scales, we'll want to standardize. And we still have missing values for which the `SimpleImputer()` will take care of.\n",
    "\n",
    "#### Categorical Features\n",
    "\n",
    "These features will need to be encoded. Because of the high cardinality of the `Location` column we'll use the `LabelEncoder()` separately (it doesn't accept more than one column at a time and can't be used in the pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column names\n",
    "weather_drop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the numeric features\n",
    "numeric_features = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', \n",
    "                    'WindSpeed9am','WindSpeed3pm', 'Humidity9am', \n",
    "                    'Humidity3pm', 'Pressure9am','Pressure3pm', \n",
    "                    'Temp9am', 'Temp3pm', 'RISK_MM']\n",
    "\n",
    "# Create the transformer (impute, scale)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define the categorical features\n",
    "categorical_features = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal', OrdinalEncoder())])\n",
    "\n",
    "# Define how the numeric and categorical features will be transformed\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Define the pipeline steps, including the classifier\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                  ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Matrix, Target Array\n",
    "\n",
    "We have a couple of final steps before we fit the model, and that is to create the feature matrix and create and encode the target array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature matrix \n",
    "X = weather_drop.drop('RainTomorrow', axis=1)\n",
    "\n",
    "# Create and encode the target array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_enc = LabelEncoder()\n",
    "y=label_enc.fit_transform(weather_drop['RainTomorrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split utility\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "clf.fit(X_train,y_train)\n",
    "print('Validation Accuracy', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! We achieved 100% accuracy. But is this too good to be true? Yes - anytime you have a model with very high accuracy, then you likely have a problem and that problem is probably data leakage of some type. Let's look at the feature importances and see where the problem is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (order in which they were preprocessed)\n",
    "features_order = numeric_features + categorical_features\n",
    "\n",
    "# Determine the importances\n",
    "importances = pd.Series(clf.steps[1][1].feature_importances_, features_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 7\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey')\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mod1_obj1_top7feature_leaky.png](https://raw.githubusercontent.com/LambdaSchool/data-science-canvas-images/main/unit_2/sprint_3/mod1_obj1_top7feature_leaky.png)\n",
    "\n",
    "Well, it looks like the model was essentially fit on a single feature, which must because that predictor was related to the target array. Spoiler: one of the features is leaking information to the model. It the `RISK_MM` column which is essentially how much rain was recorded the following day. \n",
    "\n",
    "We'll remove this column, run the model again, and calculate the features importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'RISK_MM' column\n",
    "X_noriskmm = X.drop('RISK_MM', axis=1)\n",
    "\n",
    "# Create the new training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_noriskmm, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Drop the 'RISK_MM' column from the numeric_features\n",
    "numeric_features = numeric_features.remove('RISK_MM')\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train,y_train)\n",
    "print('Validation Accuracy (with no \"RISK_MM\")', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better! The accuracy is still high, but much more reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "\n",
    "# Features (order in which they were preprocessed)\n",
    "numeric_features = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', \n",
    "                    'WindSpeed9am','WindSpeed3pm', 'Humidity9am', \n",
    "                    'Humidity3pm', 'Pressure9am','Pressure3pm', \n",
    "                    'Temp9am', 'Temp3pm']\n",
    "\n",
    "categorical_features = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
    "features_order = numeric_features + categorical_features\n",
    "\n",
    "importances = pd.Series(clf.steps[1][1].feature_importances_, features_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "\n",
    "n = 7\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey')\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mod1_obj1_top7feature_NOleaky.png](https://raw.githubusercontent.com/LambdaSchool/data-science-canvas-images/main/unit_2/sprint_3/mod1_obj1_top7feature_NOleaky.png)\n",
    "\n",
    "## Challenge\n",
    "\n",
    "In the above example, we removed the `RISK_MM` column but this takes away information that we might use in our model. For this challenge, think of a way you could group the values in this column and use it as the target for model. Can we predict how much rain is received instead of just a true/false prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* [Kaggle: What is Data Leakage?](https://www.kaggle.com/dansbecker/data-leakage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

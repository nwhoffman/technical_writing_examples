{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "So far, we have fit a simple linear regression with one feature and a multiple linear regression with two features. These two processes were relatively easy to do because we used the scikit-learn predictor to fit models to our data.\n",
    "\n",
    "But, how do these estimators actually determine the parameters (regression coefficients) for our models? The answer includes a lot of math! In this objective, we'll take a closer look at the mathematics behind an ordinary least squares (OLS) regression and how it works.\n",
    "\n",
    "### Sum of squared errors\n",
    "\n",
    "The ordinary least squares method is based on minimizing the sum of the squared error. This error is the difference between the observed dependent variable and the value predicted by the linear model. The OLS method estimates the slope and intercept parameters for a line that minimizes the sum of the distance between the line and the observed data.\n",
    "\n",
    "![OLS plot](https://raw.githubusercontent.com/LambdaSchool/data-science-canvas-images/main/unit_2/sprint_1/mod2_obj3_OLS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math: sum of squares\n",
    "\n",
    "Looking at the plot above, we see each data point is some distance away from the line, as measured along the y axis. To determine how well a given line fits the observed data, we sum the square of the distance of each point from the line. Some of the data is above the line (positive distance) and some is below (negative distance); we square this distance so that the negative values don't cancel out the positive values.\n",
    "\n",
    "<script src=\"https://i.upmath.me/latex.js\"></script>\n",
    "<p>The form of the equation for a line takes many forms and uses different variables. We’ve been using $y = \\beta_0 + \\beta_1X_1$ and we’ll continue with this format. But be aware there are other variables used for the parameters in the equation of a line.</p>\n",
    "<p>We’ll start with an equation for a line with the form:</p>\n",
    "<p>$$y = \\beta_0 + \\beta_1X$$</p>\n",
    "<p>We want to estimate the parameters for $\\beta_0$ and $\\beta_1X$. For each data point $i$ in our data set, we want to find the value predicted by using the coefficients $\\beta_0$ and $\\beta_1$. The predicted value of y would be given by:</p>\n",
    "<p>$$y_{predict} = \\beta_0 + \\beta_1x_i$$</p>\n",
    "<p>The error between the actual value $y_i$ and the predicted value $y_{predict}$ is:</p>\n",
    "<p>$$\\text{diff} = y_{i} - y_{predict} = y_{i} - (\\beta_0 + \\beta_1x_{i})$$</p>\n",
    "<p>We want to sum over <em>all</em> of the values in the data set. So we need to square this difference and then add them up:</p>\n",
    "<p>$$\\text{Sum of squares} = \\sum (y_{i} - (\\beta_0 + \\beta_1 x_{i}))^2$$</p>\n",
    "<p>Now comes the fun part: we need to apply some math to the above sum of squares equation to find the values of $\\alpha$ and $\\beta$ that <em>minimize</em> the sum. There are a few different ways to derive this answer, including using calculus and linear algebra. These derivations are beyond the scope of this course, so we’re going to go straight to the answer.</p>\n",
    "\n",
    "### Parameter estimates: least squares\n",
    "\n",
    "<script src=\"https://i.upmath.me/latex.js\"></script>\n",
    "<p>The values for the parameters are given by:</p>\n",
    "<p>$$\\beta_1 = \\frac{Cov[x,y]}{Var[x]}$$</p>\n",
    "<p>$$\\beta_0 = \\bar{y} - \\beta \\bar{x}$$</p>\n",
    "<p>where $\\bar{x}$ and $\\bar{y}$ are the mean values of $x$ and $y$.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along\n",
    "\n",
    "Now that we have some of the math out of the way, let's code a simple example to find the coefficients for a linear regression. Instead of using a real-world data set, it will be easier to generate a small sample data set where we determine the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Generate the sample data\n",
    "x = np.arange(25)\n",
    "delta = np.random.uniform(0,20, size=(25,))\n",
    "y = 0.4 * x + 3 + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate alpha and beta\n",
    "\n",
    "def least_squares_params(x, y):\n",
    "    '''\n",
    "    x and y: data to be fit\n",
    "    returns: the least-square values of alpha and beta\n",
    "    '''\n",
    "    # Calculate the mean of X and y\n",
    "    xmean = np.mean(x); ymean = np.mean(y)\n",
    "    \n",
    "    # Calculate the covariance for x and y, variance for x\n",
    "    xycov = (x-xmean)*(y-ymean)\n",
    "    xvar = (x-xmean)**2\n",
    "    \n",
    "    # Calculate the coefficients\n",
    "    beta_1 = sum(xycov) / sum(xvar)\n",
    "    beta_0 = ymean - (beta_1*xmean)\n",
    "    \n",
    "    print('beta_0: ', beta_0)\n",
    "    print('beta_1: ', beta_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a reasonably simple function, let's try it out on the data we generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_0:  11.01787535843764\n",
      "beta_1:  0.5507176494641995\n"
     ]
    }
   ],
   "source": [
    "# Find the estimated parameters for alpha, beta\n",
    "# given our (x, y) data set\n",
    "least_squares_params(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimated the parameters! But how do we know that they are correct? It's possible there could be an error in our function or that we didn't use the correct formula for estimating the parameters.\n",
    "\n",
    "A quick check would be to use the scikit-learn estimator and find the coefficients. We've already done this a few times, but one more time is good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_0:  11.017875358437646\n",
      "beta_1:  [0.55071765]\n"
     ]
    }
   ],
   "source": [
    "# Import the estimator class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate the class (with default parameters)\n",
    "model = LinearRegression()\n",
    "\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Intercept\n",
    "print('beta_0: ', model.intercept_)\n",
    "\n",
    "# Slope (also called the model coefficient)\n",
    "print('beta_1: ', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our estimator function above was correct. The results from the scikit-learn LinearRegression model are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "This objective covered a lot of material. The best way to continue to practice would be to try it out yourself. Following the example above, use a different data set and convince yourself that the function returns the same result as the scikit-learn LinearRegression predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* [Khan Academy: Squared Error of Regression](https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/more-on-regression/v/squared-error-of-regression-line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In the first sprint for this unit, we introduced the concept of using a validation set. This method provides a way to check or evaluate your model before needing to use a final test set. As a test set isn't always available (such as for a Kaggle competition), validation sets fill in the gap.\n",
    "\n",
    "But there are some limitations to using a single validation set. One important consideration is that you will get different results (model scores) with different validation sets. A way around this is to use more than one validation set. There are a few different ways to do this.\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "The method of cross-validation is where we divide the data into equal-sized sets; some sets are used for training and the remaining set is used for testing. For each trial, a different set is used for testing. The specific method will discuss in this objective is called *k-fold cross-validation*.\n",
    "\n",
    "#### K-fold Cross-Validation\n",
    "\n",
    "For this method, we divide data into *k* equal sets or *folds*; a typical number is 5 or 10 folds. For each fold, we train on k-1 folds and test on the remaining fold. For example, if k=5, you would train on four folds and test on the fifth fold. With each trial, train on the next k-1 folds and test on the remaining fold. For k=5, there will be five trials, with five different test sets, with an accuracy score for each.\n",
    "\n",
    "specifically k-fold cross-validation. For a quick review, k-fold cross-validation in where the data is divided into *k* equal sets or *folds*. For each fold, we train on k-1 folds and test on the remaining fold. For example, if k=5, you would train on four folds and test on the fifth fold. With each trial, train on the next k-1 folds and test on the remaining fold. For k=5, there will be five trials, with five different test sets, with an accuracy score for each.\n",
    "\n",
    "What we didn't cover as much was *why* we use cross-validation and how it can be used to select the hyperparameters which result in the best model.\n",
    "\n",
    "### Cross-validation and Pipelines\n",
    "\n",
    "As was introduced in lecture, we could hold out a validation set: separate data into training, validation, and testing. Train the model with the training set, validate the model parameters with the validation set, and then do the final testing on the test set.\n",
    "\n",
    "One issue with this method is that if you need to standardize your variables, and you standardize *before* splitting into training and testing sets, you will inadvertently leak some knowledge to the testing set. For example, if you are standardizing by subtracting the mean and dividing by the standard deviation, your test data will *know* these statistics about the rest of the data.\n",
    "\n",
    "For cross-validation, if you standardize your data before dividing into k-fold cross-validation sets, your test/validation set in each fold will also know something about the training data. To avoid the problem of data leakage, separate your training/testing set or cross-validation sets and then standardize. The scikit-learn `Pipeline` tool makes this process easy, by applying any preprocessing or standardizing separately to the training and testing data.\n",
    "\n",
    "In the next section, we will assemble a pipeline and then fit our model, using k-fold cross-validation to determine the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the feature matrix:  (1797, 64)\n",
      "The shape of the target array:  (1797,)\n",
      "The unique classes in the target:  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Load the digits data\n",
    "\n",
    "# The deafult with 10 classes (digits 0-9)\n",
    "digits = datasets.load_digits(n_class=10)\n",
    "\n",
    "# Create the feature matrix\n",
    "features = digits.data\n",
    "print('The shape of the feature matrix: ', features.shape)\n",
    "\n",
    "# Create the target array\n",
    "target = digits.target\n",
    "print('The shape of the target array: ', target.shape)\n",
    "print('The unique classes in the target: ', np.unique(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the standardizier\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Instantiate the classifier\n",
    "logreg = LogisticRegression(max_iter=150)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = make_pipeline(standardizer, logreg)\n",
    "\n",
    "# Instantiate the k-fold cross-validation \n",
    "kfold_cv = KFold(n_splits=5, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using k-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline, features, target,\n",
    "                           cv=kfold_cv, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cv scores:  [0.97222222 0.96944444 0.95543175 0.97493036 0.98050139]\n",
      "Mean of all cv scores:  0.9705060352831941\n"
     ]
    }
   ],
   "source": [
    "# Print the mean score\n",
    "print('All cv scores: ', cv_scores)\n",
    "\n",
    "# Print the mean score\n",
    "print('Mean of all cv scores: ', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we displayed all the scores and also the mean of the scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Look at the number of folds in the k-fold cross validation - how does changing the value affect the accuracy of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* [Scikit-learn: Standard Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "* [Scikit-learn: Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [Scikit-learn: Digits Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)\n",
    "* [Scikit-learn: KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "* [Evaluate a score by cross-validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
